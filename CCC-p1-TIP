--openstack passwd
YmM5ZWYxZDk4MGRjMWQ2

--IP
demo-1 172.26.132.113
demo-2 172.26.131.241


--instance proxy
HTTP_PROXY=http://wwwproxy.unimelb.edu.au:8000/
HTTPS_PROXY=http://wwwproxy.unimelb.edu.au:8000/
http_proxy=http://wwwproxy.unimelb.edu.au:8000/
https_proxy=http://wwwproxy.unimelb.edu.au:8000/ no_proxy=localhost,127.0.0.1,localaddress,172.16.0.0/12,.melbourne.rc.nectar.org.au,.storage.unimelb.edu.au,.cloud.unimelb.edu.au


--config proxy for docker--
sudo mkdir /etc/systemd/system/docker.service.d
sudo nano /etc/systemd/system/docker.service.d/http-proxy.conf
[Service]
Environment="HTTP_PROXY=http://wwwproxy.unimelb.edu.au:8000/"
Environment="HTTPS_PROXY=http://wwwproxy.unimelb.edu.au:8000/"
Environment="NO_PROXY=localhost,127.0.0.1,localaddress,172.16.0.0/12,.melbourne.rc.nectar.org.au,.storage.unimelb.edu.au,.cloud.unimelb.edu.au"

sudo systemctl daemon-reload
sudo systemctl show --property Environment docker

sudo systemctl restart docker
sudo docker pull wordpress


--run docker couchdb
sudo docker run -p 5984:5984 -p 9100:9100 -p 4369:4369 -d --name my-couchdb -e COUCHDB_SECRET='a192aeb9904e6590849337933b000c99' -e ERL_FLAGS="-setcookie \"a192aeb9904e6590849337933b000c99\"" -e NODENAME='172.26.132.113' -e COUCHDB_USER=admin -e COUCHDB_PASSWORD=123456 couchdb:latest
sudo docker run -p 5984:5984 -p 9100:9100 -p 4369:4369 -d --name my-couchdb -e COUCHDB_SECRET='a192aeb9904e6590849337933b000c99' -e ERL_FLAGS="-setcookie \"a192aeb9904e6590849337933b000c99\"" -e NODENAME='172.26.131.241' -e COUCHDB_USER=admin -e COUCHDB_PASSWORD=123456 couchdb:latest

sudo docker run -p 5984:5984 -p 9100:9100 -p 4369:4369 -d --name my-couchdb -e COUCHDB_SECRET='a192aeb9904e6590849337933b000c99' -e ERL_FLAGS="-setcookie \"a192aeb9904e6590849337933b000c99\"" -e NODENAME='172.26.133.62' -e COUCHDB_USER=admin -e COUCHDB_PASSWORD=123456 couchdb:latest

sudo docker exec -it my-couchdb bash
sudo docker logs my-couchdb
sudo lsof -i -P -n | grep LISTEN

erl -name bus@172.26.132.113 -setcookie 'brumbrum' -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9200
erl -name car@172.26.131.241 -setcookie 'brumbrum' -kernel inet_dist_listen_min 9100 -kernel inet_dist_listen_max 9200
** security_group port:4369
net_kernel:connect_node('car@172.26.131.241').


-- couchdb cluster
# First, get two UUIDs to use later on. Be sure to use the SAME UUIDs on all nodes.
curl http://172.26.132.113:5984/_uuids?count=2

{"uuids":["6d2e2292fe603155cb8b27ca94000991","6d2e2292fe603155cb8b27ca94000dd6"]}
# CouchDB will respond with something like:
#   {"uuids":["60c9e8234dfba3e2fdab04bf92001142","60c9e8234dfba3e2fdab04bf92001cc2"]}
# Copy the provided UUIDs into your clipboard or a text editor for later use.
# Use the first UUID as the cluster UUID.
# Use the second UUID as the cluster shared http secret.

# Create the admin user and password:
curl -X PUT http://<server-IP|FQDN>:5984/_node/_local/_config/admins/admin -d '"password"'

# Now, bind the clustered interface to all IP addresses availble on this machine
curl -X PUT http://172.26.132.113:5984/_node/_local/_config/chttpd/bind_address -d '"0.0.0.0"'

# If not using the setup wizard / API endpoint, the following 2 steps are required:
# Set the UUID of the node to the first UUID you previously obtained:
curl -X PUT http://<server-IP|FQDN>:5984/_node/_local/_config/couchdb/uuid -d '"FIRST-UUID-GOES-HERE"'

# Finally, set the shared http secret for cookie creation to the second UUID:
curl -X PUT http://<server-IP|FQDN>:5984/_node/_local/_config/couch_httpd_auth/secret -d '"SECOND-UUID-GOES-HERE"'

- The Cluster Setup API
curl -X POST -H "Content-Type: application/json" http://admin:123456@127.0.0.1:5984/_cluster_setup -d '{"action": "enable_cluster", "bind_address":"0.0.0.0", "username": "admin", "password":"123456", "node_count":"2"}'

curl -X POST -H "Content-Type: application/json" http://admin:123456@172.26.132.113:5984/_cluster_setup -d '{"action": "enable_cluster", "bind_address":"0.0.0.0", "username": "admin", "password":"123456", "port": 5984, "node_count": "2", "remote_node": "172.26.131.241", "remote_current_user": "admin", "remote_current_password": "123456" }'

***
curl -X POST -H "Content-Type: application/json" http://admin:123456@172.26.133.62:5984/_cluster_setup -d '{"action": "enable_cluster", "bind_address":"0.0.0.0", "username": "admin", "password":"123456", "port": 5984, "node_count": "3", "remote_node": "172.26.131.241", "remote_current_user": "admin", "remote_current_password": "123456" }'

curl -X POST -H "Content-Type: application/json" http://admin:123456@172.26.132.113:5984/_cluster_setup -d '{"action": "add_node", "host":"172.26.130.93", "port": 5984, "username": "admin", "password":"123456"}'

curl -X POST -H "Content-Type: application/json" "http://admin:123456@${IP1}:5984/_cluster_setup" -d '{"action": "add_node", "host":"${IP4}", "port": 5984, "username": "admin", "password":"123456"}'


***
curl -X POST -H "Content-Type: application/json" http://admin:123456@172.26.132.113:5984/_cluster_setup -d '{"action": "add_node", "host":"172.26.133.62", "port": 5984, "username": "admin", "password":"123456"}'


curl -XGET "http://admin:123456@172.26.132.113:5984/"

curl -X POST -H "Content-Type: application/json" http://admin:123456@172.26.132.113:5984/_cluster_setup -d '{"action": "finish_cluster"}'

curl http://admin:123456@172.26.132.113:5984/_cluster_setup

curl http://admin:123456@172.26.132.113:5984/_membership

- The Cluster config

curl -s admin:123456@localhost:5984/test1 | jq .

curl -s admin:123456@localhost:5984/test1/_shards | jq .



--Web
我这里重新写了一个网站的框架。现在这个还没有美工，但是可以处理json文件，返回top词频（或者我们选定的某些词的词频）。在服务器上安装django后使用python manage.py runserver 0.0.0.0:8000 就可以运行

-Web image push to docker-hub
// build image
$ docker-compose build
$ docker login
username: acherking
passwd: J-*8ePDDUjCnz%M
$ docker tag web_image_web acherking/cccp2web:[一个tag(版本号/latest)]
//例如:docker tag web_image_web acherking/cccp2web:1.2
$ docker push acherking/cccp2web:[your_tag]
$ docker logout


--swarm
ubuntu@demo-1:~$ sudo docker swarm init --advertise-addr 172.26.132.113
Swarm initialized: current node (przir2ckcypwqn587znt4imf3) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-1h84n38b35xzff58tb3hh96w4dqnxv1oja7q4vj05r7qlt9fd7-832d3hjjmsbfve9nyho8zgl24 172.26.132.113:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

sudo docker service create -d \
  --replicas=2 \
  --name web-service \
  --mount type=bind,source=/home/ubuntu/web_image,destination=/code \
  -p 8000:8000 \
  acherking/cccp2web:web_image \
  python manage.py runserver 0.0.0.0:8000

sudo docker service create -d \
  --replicas=3 \
  --name web-service \
  -p 8000:8000 \
  acherking/cccp2web:2.0 \
  python manage.py runserver 0.0.0.0:8000

sudo docker service update --image acherking/cccp2web:2.2 web-service

sudo docker run -p 8000:8000 -d -v /home/ubuntu/web_image:/code --name web-server acherking/cccp2web:web_image python manage.py runserver 0.0.0.0:8000


--Twitter Harvest

nohup python3 -u melbourne_data.py >> data/mel_data1.log 2>>&1 &
nohup python3 -u australia_data.py >> data/aus_data1.log 2>>&1 &

sudo docker service create -d \
  --replicas=1 \
  --name twitter-harvester-mel \
  --mount type=bind,source=/home/ubuntu/tweet_harvester/data,destination=/tweet_harvester/data \
  acherking/cccp2py:1.1 \
  python3 -u melbourne_data.py

sudo docker run -v /home/ubuntu/tweet_harvester/data:/tweet_harvester/data --name twitter-harvester -e HTTP_PROXY=http://wwwproxy.unimelb.edu.au:8000/ -e HTTPS_PROXY=http://wwwproxy.unimelb.edu.au:8000/ -e https_proxy=http://wwwproxy.unimelb.edu.au:8000/ -e http_proxy=http://wwwproxy.unimelb.edu.au:8000/ acherking/cccp2py:1 python3 -u australia_data.py


sudo docker service create -d \
  --replicas=1 \
  --name twitter-harvester-au \
  --mount type=bind,source=/home/ubuntu/tweet_harvester/data,destination=/tweet_harvester/data \
  acherking/cccp2py:1.1 \
  python3 -u australia_data.py


--scale down
export IP1=172.26.132.113
export IP4=172.26.130.93
export ref=1-967a00dff5e02add41819138abb3284d

curl "http://admin:123456@${IP1}:5984/_node/_local/_nodes/couchdb@${IP4}"

curl -X DELETE "http://admin:123456@${IP1}:5984/_node/_local/_nodes/couchdb@${IP4}?rev=${ref}"




